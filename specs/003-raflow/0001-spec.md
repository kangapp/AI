# 构建下一代语音交互工具：基于 Tauri v2 与 ElevenLabs Scribe v2 Realtime API 的深度技术架构报告

## 报告摘要

随着大语言模型（LLM）与语音识别技术的即时性（Real-time）突破，人机交互（HCI）正经历从"键鼠主导"向"语音流主导"的范式转移。以 Wispr Flow 为代表的新一代生产力工具，通过打破应用程序边界，将语音听写转化为一种系统级的环境服务（Ambient Service），彻底重构了文本输入体验。

本报告旨在响应构建类似 Wispr Flow 工具的技术需求，深入剖析基于 Tauri v2 框架与 ElevenLabs Scribe v2 Realtime API 的全栈实现方案。本报告长达两万字，将详尽探讨从底层音频采集管道的构建、实时重采样算法的优化、WebSocket 双工通信的稳健性设计，到操作系统层面的无障碍（Accessibility）API 集成与光标追踪技术。

针对"在当前光标位置插入文本，若不可输入则回退至剪贴板"这一核心需求，报告将提供基于 Rust 生态的系统级解决方案，并对比不同技术路径的优劣。此外，报告包含完整的 TypeScript 客户端参考实现与 Rust 后端架构蓝图，旨在为开发高并发、低延迟的桌面级语音助手提供权威的工程指南。

---

## 第一部分：核心引擎解析——ElevenLabs Scribe v2 Realtime API

在构建实时语音转录工具时，核心识别引擎的选择直接决定了用户体验的上限。ElevenLabs 推出的 Scribe v2 Realtime 模型不仅仅是一个传统的语音转文本（STT）引擎，它被专门设计用于"代理"（Agentic）场景，具备极低的延迟和上下文感知的预测能力。

### 1.1 Scribe v2 的技术特性与优势

Scribe v2 在架构上区别于早期的 Whisper 模型，它引入了"负延迟"（Negative Latency）概念，实际上是指模型具备强大的下一词预测能力，能够在音频尚未完全结束时即推断出后续文本，从而在视觉上呈现出极快的响应速度。

| 特性 | Scribe v2 Realtime 指标 | 对本项目的意义 |
|------|------------------------|--------------|
| 延迟 | < 150ms (不含网络往返) | 确保用户说话与屏幕显示文字之间无感知停顿，实现"跟手"体验。 |
| 音频格式 | PCM 16-bit, 16kHz (推荐) | 减少服务端转码开销，要求客户端进行本地重采样。 |
| VAD (语音活动检测) | 内置且可配置 | 自动切分语音片段，支持手动提交（Manual Commit）以适应类似对讲机（Push-to-Talk）的交互模式。 |
| 输出事件 | partial (部分) 与 committed (提交) | 支持 UI 呈现"灰字变黑字"的动态效果，增强交互反馈。 |
| 多语言 | 90+ 语言支持，自动检测 | 允许用户在多语言环境下无缝切换，无需手动更改设置。 |

### 1.2 WebSocket 通信协议深度剖析

Scribe v2 仅通过 WebSocket 协议提供服务，这意味着我们需要建立一个全双工的长连接。理解其握手、数据流和事件模型是开发客户端的基础。

#### 1.2.1 连接握手与会话初始化

连接端点为 `wss://api.elevenlabs.io/v1/speech-to-text/realtime`。鉴权方式通常有两种：HTTP Header 中的 `xi-api-key` 或 URL 查询参数中的 `token`。对于桌面客户端应用，建议在后端获取临时 Token 或通过代理层转发，以保护 API Key 不被直接暴露（尽管桌面应用逆向风险始终存在）。

一旦连接建立，服务端会立即发送 `session_started` 消息。这是一个关键的同步点，客户端必须在接收到此消息后，才开始流式传输音频数据。

```json
{
  "message_type": "session_started",
  "session_id": "unique_session_id_xyz",
  "config": {
    "sample_rate": 16000,
    "model_id": "scribe_v2_realtime",
    "vad_threshold": 0.4
  }
}
```

#### 1.2.2 音频流式传输规范 (input_audio_chunk)

客户端需要将麦克风采集的音频切片并发送。Scribe v2 对音频格式有严格要求：**16kHz 采样率的原始 PCM 数据（Raw PCM）**。大多数现代麦克风默认采样率为 44.1kHz 或 48kHz，直接发送会导致识别乱码或变声，因此客户端侧的重采样（Resampling）是必不可少的环节（详见第三部分）。

音频数据必须经过 Base64 编码封装在 JSON 中发送：

```json
{
  "message_type": "input_audio_chunk",
  "audio_base_64": "UklGRiQAAABXQVZFZm10...",
  "commit": false
}
```

在此项目中，我们将采用"按需提交"策略。当用户按下热键开始录音时，`commit` 为 `false`；当用户松开热键或再次按下停止时，发送一个空音频包并将 `commit` 设为 `true`，强制模型立即进行最终推理并返回结果。

#### 1.2.3 转录事件流处理

服务端返回的数据流主要包含两类事件，前端 UI 需据此实现不同的渲染逻辑：

- **partial_transcript（部分转录）**：这是高频触发的事件，包含当前语音片段的临时识别结果。这些结果是不稳定的，随新的音频输入而变化。
  - **UI 策略**：显示为灰色或半透明文本，并在新事件到来时直接覆盖旧内容。

- **committed_transcript（已提交转录）**：这是模型确认的最终文本，经过了标点符号修正和语法优化。
  - **UI 策略**：将灰色文本转为黑色（确立状态），并追加到最终结果缓冲区。同时，这是触发"文本注入"操作的信号。

### 1.3 TypeScript 客户端参考实现

为了响应您对 TypeScript 探索的需求，以下是一个完整的 TypeScript 类实现。虽然最终架构建议将音频处理放在 Rust 后端以保证性能和后台存活能力，但此 TS 代码可用于前端原型验证或作为 Tauri 前端部分的逻辑参考。

此实现涵盖了 WebSocket 管理、从浏览器 AudioContext 获取 PCM 数据、以及 Float32 到 Int16 的转换逻辑。

```typescript
/**
 * ElevenLabs Scribe v2 Realtime Client
 * 用于处理与 ElevenLabs WebSocket API 的全双工通信
 */

// 引入必要的类型定义（假设环境支持）
interface TranscriptEvent {
  message_type: 'partial_transcript' | 'committed_transcript';
  text: string;
  created_at_ts?: number;
}

interface AudioChunk {
  message_type: 'input_audio_chunk';
  audio_base_64: string;
  commit?: boolean;
}

export class ScribeClient {
  private ws: WebSocket | null = null;
  private audioContext: AudioContext | null = null;
  private mediaStream: MediaStream | null = null;
  private processor: ScriptProcessorNode | null = null;
  private isRecording: boolean = false;

  constructor(
    private apiKey: string,
    private onPartial: (text: string) => void,
    private onCommitted: (text: string) => void,
    private onError: (err: string) => void
  ) {}

  /**
   * 启动录音会话
   */
  public async startSession() {
    if (this.isRecording) return;

    try {
      // 1. 初始化 WebSocket 连接
      // 注意：生产环境中建议通过后端代理获取临时 Token，避免暴露 API Key
      const url = `wss://api.elevenlabs.io/v1/speech-to-text/realtime?token=${this.apiKey}`;
      this.ws = new WebSocket(url);

      this.ws.onopen = () => {
        console.log('Connection established');
        this.initAudioCapture();
      };

      this.ws.onmessage = (event) => {
        const data = JSON.parse(event.data) as TranscriptEvent;
        if (data.message_type === 'partial_transcript') {
          this.onPartial(data.text);
        } else if (data.message_type === 'committed_transcript') {
          this.onCommitted(data.text);
        }
      };

      this.ws.onerror = (e) => {
        console.error('WebSocket error', e);
        this.onError('Connection error');
      };

      this.ws.onclose = () => {
        console.log('Connection closed');
        this.stopAudioCapture();
      };

      this.isRecording = true;
    } catch (err) {
      this.onError(`Failed to start: ${err}`);
    }
  }

  /**
   * 停止录音并提交最终片段
   */
  public stopSession() {
    if (!this.isRecording || !this.ws) return;

    // 发送 commit 信号
    if (this.ws.readyState === WebSocket.OPEN) {
      const commitMsg: AudioChunk = {
        message_type: 'input_audio_chunk',
        audio_base_64: '',
        commit: true
      };
      this.ws.send(JSON.stringify(commitMsg));

      // 延迟关闭以确保收到最后的 committed_transcript
      setTimeout(() => {
        this.ws?.close();
        this.stopAudioCapture();
        this.isRecording = false;
      }, 500);
    }
  }

  private async initAudioCapture() {
    try {
      // 请求麦克风权限
      this.mediaStream = await navigator.mediaDevices.getUserMedia({
        audio: {
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true
          // 注意：浏览器无法强制硬件采样率，需软件重采样
        }
      });

      // 创建 AudioContext，强制指定 16000Hz 采样率以匹配 API 要求
      // 现代浏览器支持在此处进行自动重采样
      this.audioContext = new window.AudioContext({ sampleRate: 16000 });
      const source = this.audioContext.createMediaStreamSource(this.mediaStream);

      // 使用 ScriptProcessor 处理原始 PCM (BufferSize 4096 约 256ms 延迟)
      // 生产环境建议迁移至 AudioWorklet 以避免主线程阻塞
      this.processor = this.audioContext.createScriptProcessor(4096, 1, 1);

      source.connect(this.processor);
      this.processor.connect(this.audioContext.destination);

      this.processor.onaudioprocess = (e) => {
        if (this.ws?.readyState !== WebSocket.OPEN) return;

        const inputData = e.inputBuffer.getChannelData(0);
        // Float32 -> Int16 PCM 转换
        const pcmData = this.floatTo16BitPCM(inputData);
        const base64Audio = this.arrayBufferToBase64(pcmData);

        const msg: AudioChunk = {
          message_type: 'input_audio_chunk',
          audio_base_64: base64Audio
        };
        this.ws.send(JSON.stringify(msg));
      };
    } catch (err) {
      this.onError('Microphone access denied or error');
    }
  }

  private stopAudioCapture() {
    this.mediaStream?.getTracks().forEach(track => track.stop());
    this.processor?.disconnect();
    this.audioContext?.close();
    this.mediaStream = null;
    this.processor = null;
    this.audioContext = null;
  }

  // 辅助函数：将 Web Audio API 的 Float32 (-1.0 ~ 1.0) 转换为 PCM Int16
  private floatTo16BitPCM(input: Float32Array): ArrayBuffer {
    const buffer = new ArrayBuffer(input.length * 2);
    const view = new DataView(buffer);
    for (let i = 0; i < input.length; i++) {
      // 钳位处理，防止爆音
      const s = Math.max(-1, Math.min(1, input[i]));
      // 映射到 Int16 范围 (0x7FFF = 32767)
      view.setInt16(i * 2, s < 0 ? s * 0x8000 : s * 0x7FFF, true);
    }
    return buffer;
  }

  private arrayBufferToBase64(buffer: ArrayBuffer): string {
    let binary = '';
    const bytes = new Uint8Array(buffer);
    const len = bytes.byteLength;
    for (let i = 0; i < len; i++) {
      binary += String.fromCharCode(bytes[i]);
    }
    return window.btoa(binary);
  }
}
```

---

## 第二部分：应用架构框架——Tauri v2 的战略选择

要实现一个"类似 Wispr Flow"的工具，核心诉求是轻量级、系统常驻、低资源占用以及深度系统集成。Tauri v2 凭借其独特的架构设计，成为了这一场景下的最佳选择。

### 2.1 为什么选择 Tauri v2 而非 Electron？

在构建系统托盘（System Tray）工具时，资源占用是用户最为敏感的指标。

- **内存占用**：Tauri 使用操作系统原生的 WebView（macOS 上的 WebKit，Windows 上的 WebView2），这意味着它不需要像 Electron 那样打包整个 Chromium 内核。对于一个常驻后台、仅在录音时弹出小窗口的应用，Tauri 的空闲内存占用可控制在 30MB 以内，而 Electron 通常起步即需 100MB+。

- **安全性与权限**：Tauri v2 引入了更严格的权限控制系统（Capabilities），通过 ACL（访问控制列表）精细管理前端对后端 API 的调用。对于涉及麦克风和键盘输入的敏感应用，这种设计更为稳健。

- **Rust 后端的强大生态**：这是本方案的核心优势。我们需要进行高性能的音频重采样、全局快捷键监听以及模拟键盘输入。Rust 拥有 cpal、rubato、enigo 等高性能 Crates，能直接编译为机器码运行，避免了 Node.js 在 CPU 密集型任务上的性能瓶颈。

### 2.2 整体架构设计图

本方案采用 **Rust 后端主导（Core Logic） + React 前端渲染（UI Layer）** 的分离架构。

#### Rust 后端（主进程）

- **Tray Manager**：管理托盘图标、菜单及生命周期。
- **Hotkey Service**：监听全局 Cmd+Shift+H 事件。
- **Audio Pipeline**：负责音频采集（CPAL）、重采样（Rubato）和 WebSocket 转发（Tokio-Tungstenite）。
- **Injection Engine**：负责检测当前活动窗口（Active Window）并执行文本插入或剪贴板回退逻辑。

#### React 前端（渲染进程）

- **Floating Window**：一个透明、无边框、始终置顶的窗口。
- **Visualizer**：展示录音波形和实时转录文本。
- **State Sync**：通过 Tauri Events 接收后端的转录状态更新。

---

## 第三部分：Rust 音频管道工程（Audio Pipeline Engineering）

为了克服浏览器环境下的音频采集限制（如后台节流、采样率锁定），我们将音频采集和处理逻辑完全下沉至 Rust 后端。

### 3.1 音频采集：cpal 深度集成

cpal (Cross-Platform Audio Library) 是 Rust 生态中处理音频 I/O 的事实标准。我们需要构建一个输入流（Input Stream），从默认输入设备读取音频帧。

#### 关键挑战：线程模型与非阻塞设计

cpal 的音频回调函数（Data Callback）是在一个高优先级的音频线程中运行的。如果在该回调中执行任何耗时操作（如重采样计算、网络发送、甚至互斥锁的竞争），都会导致音频缓冲区欠载（Underflow），表现为录音中的"爆音"或丢字。

#### 最佳方案：Ring Buffer（环形缓冲区）

引入 `ringbuf` 库构建一个无锁（Lock-free）的生产者-消费者模型。

- **生产者（音频线程）**：仅负责将从麦克风获取的原始 f32 样本推入 Ring Buffer，操作耗时极短（微秒级）。
- **消费者（Tokio 异步任务）**：在独立的线程中从 Ring Buffer 读取数据，进行重采样和网络发送。

### 3.2 实时重采样：48kHz 到 16kHz 的桥梁

大多数高品质麦克风工作在 48kHz，而 ElevenLabs Scribe v2 强制要求 16kHz。虽然 API 文档提到支持其他格式，但为了最佳延迟，客户端重采样是必须的。

我们将使用 `rubato` 库，它提供了极高性能的异步重采样算法。

**选择 SincFixedIn 还是 FftFixedOut？**

对于实时流，我们选择 **FftFixedIn**（快速傅里叶变换实现），因为它在处理固定大小块（Chunk）时效率最高，且引入的延迟是确定性的。

**配置策略**：将输入音频切分为 1024 帧的块，经过 rubato 处理后，输出约 341 帧（1024 * 16000 / 48000）的 16kHz 数据。

### 3.3 线程安全的音频管道实现代码

以下是 Rust 后端音频管道的核心实现逻辑，展示了如何将 cpal、ringbuf 和 tokio 结合。

```rust
// Cargo.toml 依赖:
// cpal = "0.15"
// ringbuf = "0.3"
// rubato = "0.14"
// tokio = { version = "1", features = ["full"] }

use cpal::traits::{DeviceTrait, HostTrait, StreamTrait};
use ringbuf::{HeapRb, Producer, Consumer};
use std::sync::{Arc, Mutex};
use rubato::{Resampler, FftFixedIn, InterpolationParameters, InterpolationType, WindowFunction};

pub struct AudioEngine {
    stream: Option<cpal::Stream>,
    is_running: bool,
}

impl AudioEngine {
    pub fn new() -> Self {
        Self { stream: None, is_running: false }
    }

    pub fn start_capture<F>(&mut self, on_audio_data: F) -> Result<(), String>
    where
        F: Fn(Vec<i16>) + Send + 'static + Clone,
    {
        let host = cpal::default_host();
        let device = host.default_input_device().ok_or("No input device")?;
        let config = device.default_input_config().map_err(|e| e.to_string())?;

        // 1. 初始化 Ring Buffer (容量设为 8192 足够应对网络抖动)
        let (mut producer, mut consumer) = HeapRb::<f32>::new(8192).split();

        // 2. 配置重采样器 (假设输入 48kHz -> 输出 16kHz)
        let input_rate = config.sample_rate().0 as usize;
        let target_rate = 16000;
        let chunk_size = 1024; // 输入块大小

        // 注意：rubato 初始化较重，应放在流启动前
        let params = InterpolationParameters {
            sinc_len: 256,
            f_cutoff: 0.95,
            interpolation: InterpolationType::Linear,
            oversampling_factor: 256,
            window: WindowFunction::BlackmanHarris2,
        };
        let mut resampler = FftFixedIn::<f32>::new(
            input_rate as f64 / target_rate as f64, // 转换比率
            chunk_size,
            params,
            1, // 单声道
            1
        ).unwrap();

        // 3. 构建 CPAL 输入流 (生产者)
        let stream = device.build_input_stream(
            &config.into(),
            move |data: &[f32], _: &_| {
                // 音频线程：仅推入数据，绝对禁止阻塞
                let _ = producer.push_slice(data);
            },
            |err| eprintln!("Stream error: {}", err),
            None
        ).map_err(|e| e.to_string())?;

        stream.play().map_err(|e| e.to_string())?;
        self.stream = Some(stream);

        // 4. 启动消费者线程 (处理重采样与发送)
        std::thread::spawn(move || {
            let mut input_buffer = vec![vec![0.0f32; chunk_size]; 1]; // rubato 需要 Vec<Vec<f32>>
            let mut accumulated_samples = Vec::new();

            loop {
                // 从 Ring Buffer 读取足够的数据填满一个 Chunk
                if consumer.len() >= chunk_size {
                    accumulated_samples.clear();
                    for _ in 0..chunk_size {
                        accumulated_samples.push(consumer.pop().unwrap());
                    }
                    input_buffer = accumulated_samples.clone();

                    // 执行重采样
                    if let Ok(output) = resampler.process(&input_buffer, None) {
                        // 转换 Float32 -> Int16 PCM
                        let pcm_data: Vec<i16> = output.iter().map(|&s| {
                            let s = s.clamp(-1.0, 1.0);
                            if s >= 0.0 {
                                (s * 32767.0) as i16
                            } else {
                                (s * 32768.0) as i16
                            }
                        }).collect();

                        // 回调发送数据 (通过 Channel 发给 WebSocket 线程)
                        on_audio_data(pcm_data);
                    }
                } else {
                    // 短暂休眠避免空转，1ms 足够短不影响延迟
                    std::thread::sleep(std::time::Duration::from_millis(1));
                }
            }
        });

        Ok(())
    }
}
```

---

## 第四部分：操作系统集成与文本注入策略（Active Window Injection）

这是本项目的"最后一公里"，也是最具技术挑战性的部分。需求明确指出：插入到当前 Active App 的光标位置；若不可输入，则拷贝到剪贴板。

### 4.1 核心难题：如何判断"当前光标位置不可输入"？

操作系统（尤其是 macOS）并没有提供一个简单通用的 API 来回答"当前是否有可编辑的文本框聚焦？"这一问题。不同的应用框架（Native Cocoa, Electron, Qt, Java Swing）对辅助功能 API 的支持程度参差不齐。

- **macOS**：依赖 AXUIElement (Accessibility API)。我们需要获取系统当前的 `kAXFocusedUIElementAttribute`，然后查询该元素是否具备 `kAXValue` 属性，或者是否支持 `kAXSelectedTextRangeAttribute`。如果一个元素没有选区范围属性，它通常是不可编辑的（或者应用未正确实现 Accessibility）。

- **Windows**：依赖 UI Automation。通过 `GetFocusedElement` 获取元素，并检查其 Control Pattern 是否支持 `ValuePattern` 或 `TextPattern`。

### 4.2 最佳实践方案：尝试注入与回退机制

由于准确判断"可编辑性"在技术上存在边缘情况（例如某些自定义绘制的编辑器），最佳的工程方案是**"探测 + 尝试 + 回退"**。

#### 步骤一：获取当前活动窗口信息

使用 `active-win` Crate 获取当前窗口的元数据（App Name, Title）。这主要用于黑名单过滤（例如，如果用户正在玩全屏游戏，可能不希望注入文本）。

#### 步骤二：可编辑性探测 (macOS 示例)

我们需要引入 `accessibility` 或 `core-foundation` 的 Rust 绑定。

```rust
// 伪代码逻辑：macOS Accessibility 检查
fn is_editable_element() -> bool {
    let system_wide = AXUIElementCreateSystemWide();
    let focused_element = system_wide.get_attribute(kAXFocusedUIElementAttribute);

    if let Ok(element) = focused_element {
        // 检查是否有选区范围属性，这是可编辑文本框的典型特征
        // 许多非编辑元素（如按钮）即使聚焦也不会有此属性
        let range = element.get_attribute(kAXSelectedTextRangeAttribute);
        return range.is_ok();
    }
    false
}
```

#### 步骤三：文本注入策略

我们使用 `enigo` 库来模拟键盘输入，这是跨平台的标准做法。

**策略 A：模拟打字（适用于短语）**

对于实时转录的 `partial_transcript`，我们不进行注入，只在悬浮窗显示。只有 `committed_transcript` 才进行注入。使用 `enigo.key_sequence(text)` 逐字输入。

- **优点**：兼容性最好，看起来像用户在打字。
- **缺点**：对于长段落（Scribe v2 有时一次返回很长的句子），打字速度太慢，且中间如果用户移动光标会乱码。

**策略 B：剪贴板粘贴（适用于长文本与回退逻辑）—— 推荐方案**

为了实现"回退至剪贴板"的需求，我们可以将主要逻辑统一为"剪贴板操作"，并通过模拟 Cmd+V 来尝试粘贴。

**高级实现流程（Rust）**：

1. **保存当前剪贴板状态**：使用 `arboard` 读取当前剪贴板内容（文本/图片）并暂存到内存。

2. **写入转录文本**：将 Scribe v2 返回的文本写入系统剪贴板。

3. **判断注入方式**：
   - 如果 `is_editable_element()` 返回 `true`：
     - 使用 `enigo` 发送 Command + V (macOS) 或 Ctrl + V (Windows)。
     - 等待极短时间（例如 50ms）让系统处理粘贴事件。
     - **恢复剪贴板**：将暂存的旧内容写回剪贴板，做到"无痕"注入。

   - 如果 `is_editable_element()` 返回 `false`：
     - 不执行粘贴。不恢复剪贴板。
     - 保留转录文本在剪贴板中，并发送系统通知告诉用户"文本已复制到剪贴板"。

这种方案完美覆盖了需求中的两个分支：能输入则输入，不能输入则留存在剪贴板供用户手动粘贴。

---

## 第五部分：前端体验——复刻 Wispr Flow 的交互设计

Wispr Flow 的精髓在于"无感"。它不是一个显眼的窗口，而是一个召之即来挥之即去的"幽灵"工具。

### 5.1 悬浮窗配置 (tauri.conf.json)

我们需要一个完全透明、无边框、始终置顶的窗口。

```json
{
  "tauri": {
    "windows": [{
      "label": "floating",
      "title": "Voice Assistant",
      "width": 400,
      "height": 150,
      "decorations": false,
      "transparent": true,
      "alwaysOnTop": true,
      "skipTaskbar": true
    }]
  }
}
```

### 5.2 鼠标穿透逻辑 (Click-through)

这是用户体验的关键。悬浮窗覆盖在屏幕下方（Dock 上方），如果它拦截了鼠标点击，会干扰用户对底层应用的操作。

Tauri v2 提供了 `set_ignore_cursor_events` API。

- **默认状态**：`ignore_cursor_events(true)`。窗口可见，显示波形和文字，但鼠标点击会直接穿透到后方的 Word/Notion/VS Code。

- **交互状态**：仅当用户将鼠标悬停在特定的"停止按钮"或"设置图标"微小区域时（通过前端 `mousemove` 事件判断），临时调用后端将 ignore 设为 false。

- **或者**，完全放弃鼠标交互，仅依靠热键控制，始终保持穿透，这是最纯粹的 Wispr Flow 体验。

### 5.3 视觉反馈设计

前端接收 Rust 发来的 `transcript-update` 事件。

- **Partial Text**：使用浅灰色（`text-gray-400`），并在末尾添加闪烁光标，模拟正在思考/生成的 AI 感。

- **Committed Text**：瞬间转为深色（`text-black` 或 `text-white`，取决于系统深色模式），并在 2 秒后淡出消失，保持界面整洁。

- **动态波形**：音频线程可以顺带计算 RMS（音量能量值），以 60fps 发送给前端。前端使用 Canvas 或 CSS 动画绘制类似 Siri 的动态波球，让用户确认麦克风正在工作。

---

## 第六部分：所需库列表与依赖配置

为了实现上述所有功能，以下是 Cargo.toml 和 package.json 的最佳依赖组合。

### 6.1 Rust Crates (后端)

| Crate 名称 | 版本 | 用途 |
|-----------|------|-----|
| tauri | 2.0.0 | 核心框架，启用 tray-icon, protocol 特性。 |
| tauri-plugin-global-shortcut | 2.0.0 | 处理 Cmd+Shift+Hotkey 全局热键。 |
| tauri-plugin-clipboard-manager | 2.0.0 | 剪贴板读写操作。 |
| cpal | 0.15 | 跨平台底层音频采集。 |
| rubato | 0.14 | 高性能异步采样率转换（重采样）。 |
| ringbuf | 0.3 | 音频线程与网络线程间的无锁数据传输。 |
| tokio | 1.0 | 异步运行时，驱动 WebSocket 和长时间任务。 |
| tokio-tungstenite | 0.20 | WebSocket 客户端，处理 ElevenLabs 通信。 |
| enigo | 0.2 | 模拟键盘按键（Typing）和组合键（Cmd+V）。 |
| arboard | 3.3 | 系统剪贴板管理（比 Tauri 插件更底层，适合 Rust 侧逻辑）。 |
| active-win | 0.4 | 获取当前活动窗口信息（用于判断是否在黑名单应用）。 |
| accessibility-sys | 0.1 | (macOS专用) 调用底层 Accessibility API 判断光标位置。 |

### 6.2 Frontend Dependencies (前端)

| Package | 用途 |
|---------|------|
| @tauri-apps/api | 调用 Tauri 后端指令。 |
| react | UI 视图层构建。 |
| framer-motion | 实现平滑的文字淡入淡出和波形动画。 |
| clsx / tailwind-merge | 动态样式类管理。 |

---

## 第七部分：权限与分发注意事项

### 7.1 macOS 权限地狱

开发此类应用，macOS 的 TCC（Transparency, Consent, and Control）机制是最大痛点。

- **麦克风权限**：必须在 Info.plist 中添加 `NSMicrophoneUsageDescription`。首次启动录音时系统会弹窗询问。

- **辅助功能权限 (Accessibility)**：这是 `enigo` 模拟按键和 `active-win` 获取窗口信息所必须的。系统不会自动弹出请求对话框。应用启动时，必须使用 `AXIsProcessTrusted()` 检查权限。如果返回 false，应用应弹出一个引导窗口，展示如何打开"系统设置 -> 隐私与安全性 -> 辅助功能"并勾选本应用，甚至提供一个按钮直接打开该设置页面。

### 7.2 Windows 注意事项

Windows Defender 可能会对监听全局键盘和模拟输入的行为报警。**代码签名（Code Signing）** 是解决此问题的唯一正途。在开发阶段，可能需要将构建目录加入白名单。

---

## 结论

构建一个类似 Wispr Flow 的工具，本质上是在通过 Tauri 编排一场操作系统底层能力与云端 AI 算力的协奏曲。本方案的核心价值在于：

1. **Rust 音频管道的稳健性**：通过 Ring Buffer 和 Rubato 彻底解决了浏览器音频采集的不稳定性。

2. **智能注入策略**：通过 Accessibility 探测 + 剪贴板回退机制，优雅地解决了"在什么地方输入"的难题。

3. **Tauri v2 的轻量化**：保证了工具作为常驻服务（Systray）的合理性，不会成为系统资源的负担。

通过遵循本报告提供的架构蓝图，您可以构建出一个不仅功能完备，而且在性能和用户体验上都达到商业级水准的语音生产力工具。
